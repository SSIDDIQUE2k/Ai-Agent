# main.py
import os
import sys
import random
import time
import threading
import itertools
from datetime import datetime
from functools import lru_cache

from langchain_ollama.llms import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate
from vector import retriever

# â”€â”€â”€ MODEL & PROMPT SETUP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model = OllamaLLM(model="llama3.2", temperature=0.0)

template = '''
You are a {tone} virtual assistant. Use ONLY the snippets belowâ€”do NOT invent new information.
Speak naturally and clearly. If you donâ€™t know the answer, apologize and say so.

--- SNIPPETS ---
{reviews}

--- QUESTION ---
{question}

Assistant:
'''
prompt = ChatPromptTemplate.from_template(template)
chain = prompt | model

# â”€â”€â”€ STATE & RESPONSES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
user_tone  = "friendly"  # or â€œprofessionalâ€ if you add that feature
RESP = {
    "welcome":  "ðŸ¤– Hello! Iâ€™m here 24/7â€”ask me anything.",
    "greeting": ["ðŸ‘‹ Hi there!", "ðŸ˜Š Hey! What would you like to know?"],
    "unknown":  "ðŸ˜• Iâ€™m sorry, I donâ€™t know the answer to that.",
    "exit":     "ðŸ‘‹ Goodbye!",
    "error":    "âš ï¸ Something went wrongâ€”please try again.",
    "decline":  "ðŸ‘ Okay."
}
GREETINGS = {"hi","hello","hey","yo","greetings"}
DECLINES  = {"no","nah","nope","stop"}
BYES      = {"bye","goodbye","see ya","later"}

# â”€â”€â”€ VISITOR LOGGING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LOG_DIR  = "visitors"
LOG_FILE = os.path.join(LOG_DIR, "questions.txt")
os.makedirs(LOG_DIR, exist_ok=True)

def log_question(q: str):
    timestamp = datetime.utcnow().isoformat()
    with open(LOG_FILE, "a") as f:
        f.write(f"{timestamp}  {q}\n")

# â”€â”€â”€ SNIPPET CACHING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@lru_cache(maxsize=128)
def get_snippets(q: str) -> str:
    return retriever.invoke(q)

# â”€â”€â”€ FETCH SPINNER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def spinner(stop_ev):
    spin = itertools.cycle(['â ','â ƒ','â ‡','â §'])
    while not stop_ev.is_set():
        sys.stdout.write(f"\rðŸ” Fetching {next(spin)} ")
        sys.stdout.flush()
        time.sleep(0.1)
    sys.stdout.write("\râœ… Done fetching!   \n")

# â”€â”€â”€ CORE ANSWER LOGIC â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_answer(q: str) -> str:
    lower = q.lower().strip()

    # 1) Bye / exit
    if lower in BYES or lower in ("q","quit","exit"):
        return RESP["exit"]

    # 2) Decline
    if lower in DECLINES:
        return RESP["decline"]

    # 3) Greeting
    if any(g in lower for g in GREETINGS):
        return random.choice(RESP["greeting"])

    # 4) Retrieve snippets
    snippets = get_snippets(q)
    if not snippets:
        return RESP["unknown"]

    # 5) Invoke the model
    try:
        ans = chain.invoke({
            "tone":    user_tone,
            "reviews": snippets,
            "question": q
        }).strip()
        # If it tries to hallucinate, force unknown
        if ans.lower().startswith("iâ€™m sorry") or ans.lower().startswith("i donâ€™t know"):
            return RESP["unknown"]
        return ans
    except Exception:
        return RESP["error"]

# â”€â”€â”€ CLI INTERFACE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    print(RESP["welcome"])
    while True:
        try:
            q = input("You: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\n" + RESP["exit"])
            break

        if not q:
            continue

        # Log every question
        log_question(q)

        # Show spinner while retrieving
        stop = threading.Event()
        t = threading.Thread(target=spinner, args=(stop,))
        t.start()

        _ = get_snippets(q)  # warm/cached retrieval

        stop.set()
        t.join()

        # Compute & print answer
        answer = get_answer(q)
        print("Assistant:", answer, "\n")

        if answer == RESP["exit"]:
            break

if __name__ == "__main__":
    main()
